---
title: Glossary
description: Key terms and definitions used throughout the course
---

# Glossary

A comprehensive glossary of terms used throughout the GenAI Python Course.

---

## A

**Agent**
: An AI system that can autonomously take actions to accomplish goals, often using tools and making decisions.

**API (Application Programming Interface)**
: A set of protocols and tools for building software applications and enabling communication between systems.

**Attention Mechanism**
: A component of transformer models that allows the model to focus on relevant parts of the input when generating output.

---

## B

**Batch Processing**
: Processing multiple items together in a group rather than one at a time.

**BERT**
: Bidirectional Encoder Representations from Transformers - a transformer model designed for understanding language.

---

## C

**Chain**
: A sequence of operations or calls that are executed in order, often passing output from one to the next.

**Chunking**
: The process of splitting large documents into smaller pieces for processing or embedding.

**Context Window**
: The maximum amount of text (measured in tokens) that a language model can process at once.

**CUDA**
: A parallel computing platform by NVIDIA for GPU computing.

---

## D

**Dependency Injection**
: A design pattern where dependencies are provided to a component rather than created internally.

**Docker**
: A platform for developing, shipping, and running applications in containers.

---

## E

**Embedding**
: A numerical vector representation of text that captures semantic meaning.

**Endpoint**
: A specific URL where an API can be accessed.

---

## F

**FastAPI**
: A modern, fast Python web framework for building APIs.

**Few-shot Learning**
: Providing a model with a few examples to guide its behavior on a task.

**Fine-tuning**
: Continuing to train a pre-trained model on specific data to adapt it for a particular task.

---

## G

**GPT (Generative Pre-trained Transformer)**
: A family of large language models developed by OpenAI.

**Graph RAG**
: Retrieval-Augmented Generation that incorporates knowledge graphs for better context.

---

## H

**Hallucination**
: When an AI model generates information that is factually incorrect or made up.

**Hybrid Search**
: Combining multiple search methods (e.g., semantic + keyword) for better results.

---

## I

**Inference**
: The process of using a trained model to make predictions on new data.

---

## K

**Kubernetes (K8s)**
: An open-source container orchestration platform.

---

## L

**LangChain**
: A framework for developing applications powered by language models.

**LangGraph**
: A library for building stateful, multi-actor applications with LLMs.

**LLM (Large Language Model)**
: A neural network trained on vast amounts of text data capable of understanding and generating language.

---

## M

**Memory (in AI)**
: The ability of an AI system to retain and recall information from previous interactions.

**MLOps**
: A set of practices combining Machine Learning, DevOps, and data engineering.

---

## N

**Node (in LangGraph)**
: A function that represents a step in a graph workflow.

---

## O

**OpenAI**
: An AI research company and creator of GPT models and ChatGPT.

---

## P

**Prompt**
: The input text given to a language model to guide its response.

**Prompt Engineering**
: The practice of crafting effective prompts to get desired outputs from AI models.

**Pydantic**
: A Python library for data validation using type hints.

---

## R

**RAG (Retrieval-Augmented Generation)**
: A technique that enhances LLM responses by retrieving relevant information from external sources.

**Rate Limiting**
: Controlling the number of requests a user can make to an API within a time period.

**Reranking**
: Reordering retrieved documents by relevance before using them.

---

## S

**Semantic Search**
: Finding documents based on meaning rather than exact keyword matches.

**Streaming**
: Sending responses in chunks as they're generated rather than waiting for completion.

**System Prompt**
: Instructions given to an AI model that define its behavior and persona.

---

## T

**Temperature**
: A parameter that controls the randomness of model outputs. Higher = more random.

**Token**
: The basic unit of text that models process (roughly 3-4 characters in English).

**Transformer**
: A neural network architecture that uses attention mechanisms, the foundation of modern LLMs.

---

## V

**Vector Database**
: A database optimized for storing and querying embedding vectors.

**Virtual Environment**
: An isolated Python environment with its own dependencies.

---

## W

**Weights & Biases (W&B)**
: A platform for ML experiment tracking and model management.

---

## Z

**Zero-shot**
: Asking a model to perform a task without providing examples.
